# Human-AI-Collaboration
Mohsin. A et. al. A Unified Framework for Human–AI Collaboration in Security Operations Centers with Trusted Autonomy (2025). 
# Overview
This repository houses the supplementary materials for the research paper titled “A Unified Framework for Human–AI Collaboration in Security Operations Centers with Trusted Autonomy”. The goal of the paper is to propose and validate a unified architecture whereby human operators and AI-agents collaborate in a Security Operations Center (SOC) context, leveraging trusted autonomy to enhance situational awareness, decision-making and response in cyber defence operations.
# Contents
supplementary.ipynb — A Jupyter Notebook that demonstrates key experiments, analyses, graphs and tables from the paper.
Framework_Autonomy-Results/ — Directory containing result files, logs and artefacts generated by the framework during experimental runs.
Dataset_ACDC_Tickets-Cyberally/ — Dataset of SOC tickets used in the human–AI collaboration experiments (events labelled ACDC).
Red-Team-Attack-Protocols/ — Protocol definitions used to simulate adversarial behaviour and threat scenarios in the SOC environment.
LICENSE — MIT licence governing the use of this code and materials.
# Getting Started
Prerequisites
Python 3.8+ (tested on 3.9)
Jupyter Notebook
Required libraries: pandas, numpy, scikit-learn, matplotlib, seaborn, networkx, torch (if deep learning modules used)
Optionally: Docker (if you choose to containerise the experiments)

# Installation

Clone the repository:
git clone https://github.com/ahmadspm/Human-AI-Collaboration.git
cd Human-AI-Collaboration

(Optional) Create and activate a virtual environment:
python3 -m venv venv
source venv/bin/activate    # on Linux/macOS
.\venv\Scripts\activate     # on Windows
Install dependencies:
pip install -r requirements.txt
Note: If requirements.txt is not present, manually install the libraries listed above.
Usage
Open supplementary.ipynb in Jupyter and run the cells sequentially to reproduce the key figures, graphs and tables from the paper.

To explore the dataset, inspect Dataset_ACDC_Tickets-Cyberally/.

To examine the red-team protocols, look inside Red-Team-Attack-Protocols/.

Result logs and artefacts can be found under Framework_Autonomy-Results/.

You may extend the experiments by modifying the notebooks or implementing new modules, for example different AI-agent types or human–AI interface variations.

# Contribution

Contributions, issues or suggestions are welcomed. If you find a bug or want to propose an enhancement, please open an issue or submit a pull request. Please ensure your changes align with the MIT licence and include clear documentation and test coverage.

Licence

This project is licensed under the MIT Licence — see the LICENSE file for details.

# Citation

If you use this repository or its contents in your research, please cite the associated paper as:

Mohsin. A et. al. A Unified Framework for Human–AI Collaboration in Security Operations Centers with Trusted Autonomy (2025). 



