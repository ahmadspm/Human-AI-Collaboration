{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SpLM6qSHVk6A1NC_5tJL_4lJnFKHlhJR",
      "authorship_tag": "ABX9TyMp25KTWVQxEbibU3OJ5xxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadspm/Human-AI-Collaboration/blob/main/supplementary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juv295-1nZU9"
      },
      "outputs": [],
      "source": [
        "# Google Colab notebook cell: Red Team log processing for supplementary materials\n",
        "# Paste the whole block into a single Colab cell and run.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.api import types as ptypes\n",
        "import zipfile\n",
        "\n",
        "# --- Config: edit filenames here if needed ---\n",
        "file_event3 = \"/content/ACDC Red Team Activity Logs (4).xlsx\"       # upload this file to Colab\n",
        "file_event4 = \"/content/ACDC Red Team -TACTICS MITRE-2 (2).xlsx\"   # upload this file to Colab\n",
        "\n",
        "out_dir = Path(\"/content/supplementary_redteam\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Helper functions ---\n",
        "def anonymize_text(s, ip_map, host_map, domain_map):\n",
        "    if pd.isna(s):\n",
        "        return s\n",
        "    text = str(s)\n",
        "    # replace IPs\n",
        "    def repl_ip(match):\n",
        "        ip = match.group(0)\n",
        "        if ip not in ip_map:\n",
        "            ip_map[ip] = f\"REDACTED_IP_{len(ip_map)+1}\"\n",
        "        return ip_map[ip]\n",
        "    text = re.sub(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b', repl_ip, text)\n",
        "    # replace host-like tokens (heuristic)\n",
        "    def repl_host(match):\n",
        "        host = match.group(0)\n",
        "        if host not in host_map:\n",
        "            host_map[host] = f\"REDACTED_HOST_{len(host_map)+1}\"\n",
        "        return host_map[host]\n",
        "    text = re.sub(r'\\b[A-Za-z0-9\\-_]*?(?:host|PLC|workstation|server|pc|vm|node)[A-Za-z0-9\\-_]*\\b', repl_host, text, flags=re.IGNORECASE)\n",
        "    # replace common domain names\n",
        "    def repl_dom(match):\n",
        "        dom = match.group(0)\n",
        "        if dom not in domain_map:\n",
        "            domain_map[dom] = f\"REDACTED_DOMAIN_{len(domain_map)+1}\"\n",
        "        return domain_map[dom]\n",
        "    text = re.sub(r'\\b[a-zA-Z0-9.-]+\\.(?:com|net|org|local|corp|lan|io|dev|gov|edu)\\b', repl_dom, text)\n",
        "    return text\n",
        "\n",
        "def standardize_df(df):\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    col_map = {}\n",
        "    for cand in ['start_time','start','timestamp','time','ts']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'start_time'; break\n",
        "    for cand in ['end_time','end','finish']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'end_time'; break\n",
        "    for cand in ['phase','stage','attack_phase']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'phase'; break\n",
        "    for cand in ['action','command','activity','description']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'action'; break\n",
        "    for cand in ['actor','operator','user']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'actor'; break\n",
        "    for cand in ['tactic','mitre_tactic']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'tactic'; break\n",
        "    for cand in ['technique','mitre_technique']:\n",
        "        if cand in lower:\n",
        "            col_map[lower[cand]] = 'technique'; break\n",
        "    df = df.rename(columns=col_map)\n",
        "    return df\n",
        "\n",
        "def load_best_sheet(path):\n",
        "    xls = pd.ExcelFile(path)\n",
        "    best = None; best_count = -1\n",
        "    for s in xls.sheet_names:\n",
        "        tmp = pd.read_excel(xls, sheet_name=s)\n",
        "        if tmp.shape[0] > best_count:\n",
        "            best_count = tmp.shape[0]; best = tmp\n",
        "    return best\n",
        "\n",
        "def try_parse_datetime(col):\n",
        "    res = pd.to_datetime(col, errors='coerce', utc=False)\n",
        "    if ptypes.is_datetime64_any_dtype(res):\n",
        "        return res\n",
        "    res = pd.to_datetime(col, errors='coerce', dayfirst=True, utc=False)\n",
        "    if ptypes.is_datetime64_any_dtype(res):\n",
        "        return res\n",
        "    try:\n",
        "        numeric = pd.to_numeric(col, errors='coerce')\n",
        "        mask = numeric.notna()\n",
        "        res = pd.Series([pd.NaT]*len(col))\n",
        "        res[mask] = pd.to_timedelta(numeric[mask], unit='D') + pd.Timestamp('1899-12-30')\n",
        "        return res\n",
        "    except Exception:\n",
        "        return pd.Series([pd.NaT]*len(col))\n",
        "\n",
        "def to_utc_elementwise(ts):\n",
        "    if pd.isna(ts):\n",
        "        return pd.NaT\n",
        "    try:\n",
        "        if isinstance(ts, pd.Timestamp):\n",
        "            if ts.tzinfo is None:\n",
        "                return ts.tz_localize('Australia/Perth').tz_convert('UTC')\n",
        "            else:\n",
        "                return ts.tz_convert('UTC')\n",
        "        else:\n",
        "            parsed = pd.to_datetime(ts, errors='coerce')\n",
        "            if pd.isna(parsed):\n",
        "                return pd.NaT\n",
        "            if parsed.tzinfo is None:\n",
        "                return parsed.tz_localize('Australia/Perth').tz_convert('UTC')\n",
        "            else:\n",
        "                return parsed.tz_convert('UTC')\n",
        "    except Exception:\n",
        "        try:\n",
        "            parsed = pd.to_datetime(ts, errors='coerce')\n",
        "            if pd.isna(parsed):\n",
        "                return pd.NaT\n",
        "            return parsed.tz_localize('Etc/GMT-8').tz_convert('UTC')\n",
        "        except Exception:\n",
        "            return pd.NaT\n",
        "\n",
        "def process_event(path, event_label):\n",
        "    df = load_best_sheet(path)\n",
        "    df = standardize_df(df)\n",
        "    if 'start_time' in df.columns:\n",
        "        parsed = try_parse_datetime(df['start_time'])\n",
        "        df['start_time_parsed'] = parsed.apply(to_utc_elementwise)\n",
        "    else:\n",
        "        df['start_time_parsed'] = pd.NaT\n",
        "    if 'end_time' in df.columns:\n",
        "        parsed2 = try_parse_datetime(df['end_time'])\n",
        "        df['end_time_parsed'] = parsed2.apply(to_utc_elementwise)\n",
        "    else:\n",
        "        df['end_time_parsed'] = pd.NaT\n",
        "    def compute_dur(row):\n",
        "        s = row['start_time_parsed']\n",
        "        e = row['end_time_parsed']\n",
        "        try:\n",
        "            if pd.isna(s) or pd.isna(e):\n",
        "                return 0.0\n",
        "            return (e - s).total_seconds()\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "    df['duration_s'] = df.apply(compute_dur, axis=1)\n",
        "    df['event_id'] = event_label\n",
        "    if 'phase' not in df.columns:\n",
        "        df['phase'] = np.where(df['action'].astype(str).str.contains('recon|scan|enumerate', case=False, na=False), 'Reconnaissance', 'Execution')\n",
        "    ip_map, host_map, domain_map = {}, {}, {}\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            df[col] = df[col].apply(lambda x: anonymize_text(x, ip_map, host_map, domain_map))\n",
        "    return df, ip_map, host_map, domain_map\n",
        "\n",
        "# --- Run processing for both events ---\n",
        "df3, ip_map3, host_map3, domain_map3 = process_event(file_event3, 'Event3')\n",
        "df4, ip_map4, host_map4, domain_map4 = process_event(file_event4, 'Event4')\n",
        "\n",
        "# Save cleaned CSVs\n",
        "df3.to_csv(out_dir / \"event3_redteam.csv\", index=False)\n",
        "df4.to_csv(out_dir / \"event4_redteam.csv\", index=False)\n",
        "\n",
        "# Create simple phase summaries\n",
        "def phase_summary(df):\n",
        "    grp = df.groupby('phase').agg(\n",
        "        n_actions=('action','count'),\n",
        "        total_duration_min=('duration_s', lambda x: x.sum()/60.0),\n",
        "        mean_duration_min=('duration_s', lambda x: x.mean()/60.0)\n",
        "    ).reset_index().sort_values('total_duration_min', ascending=False)\n",
        "    return grp\n",
        "\n",
        "summary3 = phase_summary(df3)\n",
        "summary4 = phase_summary(df4)\n",
        "summary3.to_csv(out_dir / \"event3_phase_summary.csv\", index=False)\n",
        "summary4.to_csv(out_dir / \"event4_phase_summary.csv\", index=False)\n",
        "\n",
        "# Generate Gantt-style PNGs (simple visualization)\n",
        "def create_gantt(df, out_png, title):\n",
        "    plot_df = df[df['start_time_parsed'].notna()].copy()\n",
        "    if plot_df.empty:\n",
        "        return None\n",
        "    plot_df = plot_df.sort_values('start_time_parsed').reset_index(drop=True)\n",
        "    plot_df['y'] = range(len(plot_df))\n",
        "    fig, ax = plt.subplots(figsize=(10, max(3, 0.25*len(plot_df))))\n",
        "    for _, row in plot_df.iterrows():\n",
        "        start = row['start_time_parsed'].to_pydatetime()\n",
        "        dur = row['duration_s']\n",
        "        if dur <= 0:\n",
        "            dur = 60\n",
        "        ax.barh(row['y'], dur/60.0, left=start, height=0.6)\n",
        "    ax.set_yticks(plot_df['y'])\n",
        "    labels = plot_df['phase'].astype(str) + \" | \" + plot_df.get('action', pd.Series(['']*len(plot_df))).astype(str)\n",
        "    ax.set_yticklabels(labels)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel('Time (UTC)')\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(out_png, dpi=200)\n",
        "    plt.close(fig)\n",
        "    return out_png\n",
        "\n",
        "gantt3 = create_gantt(df3, out_dir/\"event3_gantt.png\", \"Event 3 — Red Team Attack Timeline (UTC)\")\n",
        "gantt4 = create_gantt(df4, out_dir/\"event4_gantt.png\", \"Event 4 — Red Team Attack Timeline (UTC)\")\n",
        "\n",
        "# README + privacy note\n",
        "readme_text = f\"\"\"\n",
        "Red Team Supplementary Package\n",
        "Files:\n",
        "- event3_redteam.csv: cleaned, anonymized action log for Event 3 (timestamps converted from AWST to UTC).\n",
        "- event4_redteam.csv: cleaned, anonymized action log for Event 4 (timestamps converted from AWST to UTC).\n",
        "- event3_phase_summary.csv, event4_phase_summary.csv: per-phase statistics (n_actions, total_duration_min, mean_duration_min).\n",
        "- event3_gantt.png, event4_gantt.png: Gantt-style attack timelines (UTC).\n",
        "\n",
        "Redactions: IPs/hostnames/domains replaced with REDACTED_* tokens.\n",
        "\n",
        "Notes: Timestamps originally AWST (UTC+8). Durations computed where end timestamps available.\n",
        "\"\"\"\n",
        "(out_dir / \"README_redteam_supplement.md\").write_text(readme_text)\n",
        "(out_dir / \"privacy_note.txt\").write_text(\"Sensitive items redacted. See README.\")\n",
        "\n",
        "# Zip the package for upload\n",
        "zipf = out_dir / \"redteam_supplementary_package.zip\"\n",
        "with zipfile.ZipFile(zipf, 'w') as z:\n",
        "    for f in out_dir.glob(\"*\"):\n",
        "        if f.name == zipf.name:\n",
        "            continue\n",
        "        z.write(f, arcname=f.name)\n",
        "\n",
        "print(\"Saved package to:\", zipf)\n",
        "print(\"Event3 Gantt:\", gantt3)\n",
        "print(\"Event4 Gantt:\", gantt4)\n",
        "print(\"Anonymization counts (event3):\", len(ip_map3), len(host_map3), len(domain_map3))\n",
        "print(\"Anonymization counts (event4):\", len(ip_map4), len(host_map4), len(domain_map4))\n",
        "\n",
        "# Display phase summaries\n",
        "print(\"\\nEvent 3 phase summary:\")\n",
        "display(summary3)\n",
        "print(\"\\nEvent 4 phase summary:\")\n",
        "display(summary4)\n"
      ]
    }
  ]
}